{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qrDJgr5ngtqx",
    "papermill": {
     "duration": 0.004443,
     "end_time": "2022-11-11T08:46:48.019499",
     "exception": false,
     "start_time": "2022-11-11T08:46:48.015056",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PasDGal√®re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-11T12:18:57.654968Z",
     "iopub.status.busy": "2022-11-11T12:18:57.653997Z",
     "iopub.status.idle": "2022-11-11T12:18:57.688915Z",
     "shell.execute_reply": "2022-11-11T12:18:57.687095Z",
     "shell.execute_reply.started": "2022-11-11T12:18:57.654825Z"
    },
    "id": "by-H15ORgtq1",
    "papermill": {
     "duration": 1.688634,
     "end_time": "2022-11-11T08:46:49.712044",
     "exception": false,
     "start_time": "2022-11-11T08:46:48.02341",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import model_selection, metrics, ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "use_cuda = torch.cuda.is_available()\n",
    "use_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "96fKAobYhLhH",
    "outputId": "a236e128-5ff2-4ad5-ab48-9b962810891a"
   },
   "outputs": [],
   "source": [
    "path = 'C:/Users/matteo/Desktop/accenture_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L65ZXkVagtq4",
    "papermill": {
     "duration": 0.003519,
     "end_time": "2022-11-11T08:46:49.719635",
     "exception": false,
     "start_time": "2022-11-11T08:46:49.716116",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "qu1l_dBAamo3"
   },
   "outputs": [],
   "source": [
    "# products and cities\n",
    "df_products = pd.read_csv(path + \"product_attributes.csv\", sep=\",\")\n",
    "\n",
    "df_cities = pd.read_csv(path + \"cities_data.csv\", sep=\",\")\n",
    "df_cities = df_cities[['city_from_name', 'city_to_name', 'distance']]\n",
    "df_cities = df_cities.drop_duplicates()\n",
    "df_cities2 = df_cities.copy()\n",
    "df_cities2['city_from_name'] = df_cities['city_to_name']\n",
    "df_cities2['city_to_name'] = df_cities['city_from_name']\n",
    "df_cities = pd.concat([df_cities, df_cities2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "QXZC_Q4uawgu"
   },
   "outputs": [],
   "source": [
    "# read train data\n",
    "df_orders = pd.read_csv(path + \"orders.csv\", sep=\";\")\n",
    "df_orders['origin_port'] = df_orders['origin_port'].replace(['ATHENAS'], 'Athens')\n",
    "df_orders['origin_port'] = df_orders['origin_port'].replace(['BCN'], 'Barcelona')\n",
    "df_orders['logistic_hub'] = df_orders['logistic_hub'].fillna('Nohub')\n",
    "\n",
    "df = df_orders.merge(df_products, how='left', left_on='product_id', right_on='product_id', sort=True)\n",
    "df['weight'].fillna(df['weight'].median(), inplace = True)\n",
    "df['material_handling'].fillna(6, inplace=True)\n",
    "\n",
    "df = df.merge(df_cities, how='left', \n",
    "              left_on=('origin_port', 'logistic_hub'), \n",
    "              right_on=('city_from_name', 'city_to_name'), sort=True)\n",
    "df.rename(columns={'distance': 'distance_port_hub'}, inplace=True)\n",
    "df = df.drop(['city_from_name', 'city_to_name'], axis=1)\n",
    "\n",
    "df = df.merge(df_cities, how='left', \n",
    "              left_on=('logistic_hub', 'customer'), \n",
    "              right_on=('city_from_name', 'city_to_name'), sort=True)\n",
    "df.rename(columns={'distance': 'distance_hub_customer'}, inplace=True)\n",
    "df = df.drop(['city_from_name', 'city_to_name'], axis=1)\n",
    "\n",
    "df = df.merge(df_cities, how='left', \n",
    "              left_on=('origin_port', 'customer'), \n",
    "              right_on=('city_from_name', 'city_to_name'), sort=True)\n",
    "df = df.drop(['city_from_name', 'city_to_name'], axis=1)\n",
    "df['distance_port_customer'] = np.where(df['logistic_hub'] == 'Nohub', df['distance'], 0)\n",
    "\n",
    "df['distance_port_hub'].fillna(0, inplace=True)\n",
    "df['distance_hub_customer'].fillna(0, inplace=True)\n",
    "df['distance_port_customer'].fillna(0, inplace=True)\n",
    "\n",
    "df['distance_port_hub'] = np.where(np.logical_and(df['distance_port_hub'] == 0, df['distance_port_customer'] == 0), \n",
    "                                   df['distance_port_hub'].median(), df['distance_port_hub'])\n",
    "\n",
    "df['distance_hub_customer'] = np.where(np.logical_and(df['distance_hub_customer'] == 0, df['distance_port_customer'] == 0), \n",
    "                                       df['distance_hub_customer'].median(), df['distance_hub_customer'])\n",
    "\n",
    "df = df.drop(['distance', 'order_id', 'product_id'], axis=1)\n",
    "df['total_weight'] = df['weight'] * df['units']\n",
    "\n",
    "#df = df.convert_dtypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 114276 entries, 0 to 114275\n",
      "Data columns (total 13 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   origin_port             114276 non-null  object \n",
      " 1   3pl                     114276 non-null  object \n",
      " 2   customs_procedures      114276 non-null  object \n",
      " 3   logistic_hub            114276 non-null  object \n",
      " 4   customer                114276 non-null  object \n",
      " 5   units                   114276 non-null  int64  \n",
      " 6   late_order              114276 non-null  bool   \n",
      " 7   weight                  114276 non-null  float64\n",
      " 8   material_handling       114276 non-null  float64\n",
      " 9   distance_port_hub       114276 non-null  float64\n",
      " 10  distance_hub_customer   114276 non-null  float64\n",
      " 11  distance_port_customer  114276 non-null  float64\n",
      " 12  total_weight            114276 non-null  float64\n",
      "dtypes: bool(1), float64(6), int64(1), object(5)\n",
      "memory usage: 11.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# read train data\n",
    "df_test = pd.read_csv(path + \"test.csv\", sep=\";\")\n",
    "df_test['origin_port'] = df_test['origin_port'].replace(['ATHENAS'], 'Athens')\n",
    "df_test['origin_port'] = df_test['origin_port'].replace(['BCN'], 'Barcelona')\n",
    "df_test['logistic_hub'] = df_test['logistic_hub'].fillna('Nohub')\n",
    "\n",
    "df_test = df_test.merge(df_products, how='left', left_on='product_id', right_on='product_id', sort=True)\n",
    "df_test['weight'].fillna(df_test['weight'].median(), inplace = True)\n",
    "df_test['material_handling'].fillna(6, inplace=True)\n",
    "\n",
    "df_test = df_test.merge(df_cities, how='left', \n",
    "              left_on=('origin_port', 'logistic_hub'), \n",
    "              right_on=('city_from_name', 'city_to_name'), sort=True)\n",
    "df_test.rename(columns={'distance': 'distance_port_hub'}, inplace=True)\n",
    "df_test = df_test.drop(['city_from_name', 'city_to_name'], axis=1)\n",
    "\n",
    "df_test = df_test.merge(df_cities, how='left', \n",
    "              left_on=('logistic_hub', 'customer'), \n",
    "              right_on=('city_from_name', 'city_to_name'), sort=True)\n",
    "df_test.rename(columns={'distance': 'distance_hub_customer'}, inplace=True)\n",
    "df_test = df_test.drop(['city_from_name', 'city_to_name'], axis=1)\n",
    "\n",
    "df_test = df_test.merge(df_cities, how='left', \n",
    "              left_on=('origin_port', 'customer'), \n",
    "              right_on=('city_from_name', 'city_to_name'), sort=True)\n",
    "df_test = df_test.drop(['city_from_name', 'city_to_name'], axis=1)\n",
    "df_test['distance_port_customer'] = np.where(df_test['logistic_hub'] == 'Nohub', df_test['distance'], 0)\n",
    "\n",
    "df_test['distance_port_hub'].fillna(0, inplace=True)\n",
    "df_test['distance_hub_customer'].fillna(0, inplace=True)\n",
    "df_test['distance_port_customer'].fillna(0, inplace=True)\n",
    "\n",
    "df_test['distance_port_hub'] = np.where(np.logical_and(df_test['distance_port_hub'] == 0, df_test['distance_port_customer'] == 0), \n",
    "                                   df_test['distance_port_hub'].median(), df_test['distance_port_hub'])\n",
    "\n",
    "df_test['distance_hub_customer'] = np.where(np.logical_and(df_test['distance_hub_customer'] == 0, df_test['distance_port_customer'] == 0), \n",
    "                                       df_test['distance_hub_customer'].median(), df_test['distance_hub_customer'])\n",
    "\n",
    "df_test = df_test.drop(['distance', 'product_id'], axis=1)\n",
    "df_test['total_weight'] = df_test['weight'] * df_test['units']\n",
    "\n",
    "df_test = df_test.convert_dtypes()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to convert categorical var\n",
    "columns_to_dummies = ['origin_port','logistic_hub', 'customer', '3pl', 'customs_procedures']\n",
    "df = pd.get_dummies(df, columns=columns_to_dummies)\n",
    "df_test = pd.get_dummies(df_test, columns=columns_to_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "X_train, X_validation, y_train, y_validation = model_selection.train_test_split(df.drop('late_order', axis=1), \n",
    "                                                                df['late_order'], test_size=0.20, random_state=79)\n",
    "X_test = df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 91420 entries, 107396 to 38077\n",
      "Data columns (total 55 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   units                    91420 non-null  int64  \n",
      " 1   weight                   91420 non-null  float64\n",
      " 2   material_handling        91420 non-null  float64\n",
      " 3   distance_port_hub        91420 non-null  float64\n",
      " 4   distance_hub_customer    91420 non-null  float64\n",
      " 5   distance_port_customer   91420 non-null  float64\n",
      " 6   total_weight             91420 non-null  float64\n",
      " 7   origin_port_Athens       91420 non-null  uint8  \n",
      " 8   origin_port_Barcelona    91420 non-null  uint8  \n",
      " 9   origin_port_Rotterdam    91420 non-null  uint8  \n",
      " 10  logistic_hub_Bratislava  91420 non-null  uint8  \n",
      " 11  logistic_hub_Dusseldorf  91420 non-null  uint8  \n",
      " 12  logistic_hub_Hamburg     91420 non-null  uint8  \n",
      " 13  logistic_hub_Liege       91420 non-null  uint8  \n",
      " 14  logistic_hub_Lille       91420 non-null  uint8  \n",
      " 15  logistic_hub_Nohub       91420 non-null  uint8  \n",
      " 16  logistic_hub_Rome        91420 non-null  uint8  \n",
      " 17  logistic_hub_Venlo       91420 non-null  uint8  \n",
      " 18  logistic_hub_Warsaw      91420 non-null  uint8  \n",
      " 19  logistic_hub_Zaragoza    91420 non-null  uint8  \n",
      " 20  customer_Amsterdam       91420 non-null  uint8  \n",
      " 21  customer_Athens          91420 non-null  uint8  \n",
      " 22  customer_Barcelona       91420 non-null  uint8  \n",
      " 23  customer_Berlin          91420 non-null  uint8  \n",
      " 24  customer_Bordeaux        91420 non-null  uint8  \n",
      " 25  customer_Bremen          91420 non-null  uint8  \n",
      " 26  customer_Bucharest       91420 non-null  uint8  \n",
      " 27  customer_Budapest        91420 non-null  uint8  \n",
      " 28  customer_Cologne         91420 non-null  uint8  \n",
      " 29  customer_Copenhagen      91420 non-null  uint8  \n",
      " 30  customer_Hanover         91420 non-null  uint8  \n",
      " 31  customer_Helsinki        91420 non-null  uint8  \n",
      " 32  customer_Lisbon          91420 non-null  uint8  \n",
      " 33  customer_Lyon            91420 non-null  uint8  \n",
      " 34  customer_Madrid          91420 non-null  uint8  \n",
      " 35  customer_Malm√∂           91420 non-null  uint8  \n",
      " 36  customer_Marseille       91420 non-null  uint8  \n",
      " 37  customer_Milan           91420 non-null  uint8  \n",
      " 38  customer_Munich          91420 non-null  uint8  \n",
      " 39  customer_Naples          91420 non-null  uint8  \n",
      " 40  customer_Paris           91420 non-null  uint8  \n",
      " 41  customer_Porto           91420 non-null  uint8  \n",
      " 42  customer_Prague          91420 non-null  uint8  \n",
      " 43  customer_Rome            91420 non-null  uint8  \n",
      " 44  customer_Stockholm       91420 non-null  uint8  \n",
      " 45  customer_Turin           91420 non-null  uint8  \n",
      " 46  customer_Valencia        91420 non-null  uint8  \n",
      " 47  customer_Vienna          91420 non-null  uint8  \n",
      " 48  3pl_v_001                91420 non-null  uint8  \n",
      " 49  3pl_v_002                91420 non-null  uint8  \n",
      " 50  3pl_v_003                91420 non-null  uint8  \n",
      " 51  3pl_v_004                91420 non-null  uint8  \n",
      " 52  customs_procedures_CRF   91420 non-null  uint8  \n",
      " 53  customs_procedures_DTD   91420 non-null  uint8  \n",
      " 54  customs_procedures_DTP   91420 non-null  uint8  \n",
      "dtypes: float64(6), int64(1), uint8(48)\n",
      "memory usage: 9.8 MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-11T12:20:25.170513Z",
     "iopub.status.busy": "2022-11-11T12:20:25.169408Z",
     "iopub.status.idle": "2022-11-11T12:20:25.899564Z",
     "shell.execute_reply": "2022-11-11T12:20:25.898383Z",
     "shell.execute_reply.started": "2022-11-11T12:20:25.170454Z"
    },
    "id": "vbwoyxM1gtq6",
    "papermill": {
     "duration": 0.014522,
     "end_time": "2022-11-11T08:46:51.565743",
     "exception": false,
     "start_time": "2022-11-11T08:46:51.551221",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# training model\n",
    "classifier = ensemble.RandomForestClassifier(n_estimators=50, max_features=\"auto\", random_state=79)\n",
    "#classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#pred = classifier.predict(X_validation)\n",
    "#metrics.accuracy_score(y_validation, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M√©ta-param√®tres tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 60 candidates, totalling 180 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'min_samples_split': 15,\n",
       " 'min_samples_leaf': 4,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 63,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_grid = {#'n_estimators' : [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)], \n",
    "               'max_features' : ['auto', 'sqrt'], \n",
    "               'max_depth' : [int(x) for x in np.linspace(30, 90, num = 10)], \n",
    "               'min_samples_split' : [10, 15, 20, 25, 30], \n",
    "               'min_samples_leaf' : [2, 3, 4, 5, 6], \n",
    "               'bootstrap' : [True, False]}\n",
    "\n",
    "classifier_random = model_selection.RandomizedSearchCV(estimator = classifier, param_distributions=random_grid, n_iter=60, \n",
    "                                        cv=3, verbose=10, random_state=79, n_jobs=-1) \n",
    "classifier_random.fit(X_train, y_train)\n",
    "best_params = classifier_random.best_params_\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8138781939096955"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_forest = ensemble.RandomForestClassifier(**best_params)\n",
    "best_forest.fit(X_train, y_train)\n",
    "pred = best_forest.predict(X_validation)\n",
    "metrics.accuracy_score(y_validation, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=58, max_features='sqrt', min_samples_leaf=4,\n",
       "                      min_samples_split=21)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "param_grid = { \n",
    "    'max_features': ['sqrt'], \n",
    "    'max_depth': [int(x) for x in np.linspace(53, 73, num = 5)],\n",
    "    'min_samples_split' : [int(x) for x in np.linspace(10, 20, num = 5)],\n",
    "    'min_samples_leaf' : [int(x) for x in np.linspace(3, 5, num = 3)], \n",
    "    'bootstrap': [True], \n",
    "}\n",
    "'''\n",
    "param_grid = { \n",
    "    'max_features': ['sqrt'], \n",
    "    'max_depth': [58],\n",
    "    'min_samples_split' : [int(x) for x in np.linspace(10, 30, num = 15)],\n",
    "    'min_samples_leaf' : [4], \n",
    "    'bootstrap': [True], \n",
    "}\n",
    "rf = ensemble.RandomForestRegressor()\n",
    "grid_search = model_selection.GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv=3, verbose=10, n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_grid = grid_search.best_estimator_\n",
    "best_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rmTgsvC4gtq6",
    "papermill": {
     "duration": 0.004901,
     "end_time": "2022-11-11T08:46:51.575208",
     "exception": false,
     "start_time": "2022-11-11T08:46:51.570307",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Save Solution\n",
    "> **Note:** Submited probabilities must be for the **True** cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8134406720336017"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = ensemble.RandomForestClassifier(n_estimators=1000, max_depth=58, max_features='sqrt', min_samples_leaf=4,\n",
    "                      min_samples_split=21, bootstrap=True, random_state=79)\n",
    "classifier.fit(X_train, y_train)\n",
    "pred = classifier.predict(X_validation)\n",
    "metrics.accuracy_score(y_validation, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-11T12:21:55.201806Z",
     "iopub.status.busy": "2022-11-11T12:21:55.201235Z",
     "iopub.status.idle": "2022-11-11T12:21:55.264849Z",
     "shell.execute_reply": "2022-11-11T12:21:55.263262Z",
     "shell.execute_reply.started": "2022-11-11T12:21:55.201757Z"
    },
    "id": "d-5KQeF0gtq7",
    "papermill": {
     "duration": 0.047754,
     "end_time": "2022-11-11T08:46:51.627348",
     "exception": false,
     "start_time": "2022-11-11T08:46:51.579594",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_proba = classifier.predict_proba(X_test.drop('order_id', axis=1))\n",
    "submission = pd.DataFrame({\"order_id\": X_test.order_id, \"late_order\": pred_proba[:,1]})\n",
    "submission.to_csv(\"submission_kaggle.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = [50, 100, 200, 500, 1000, 1500, 2000]\n",
    "for i in range(7):\n",
    "    classifier = ensemble.RandomForestClassifier(n_estimators=n[i], max_depth=35, max_features='sqrt', min_samples_leaf=2,\n",
    "                      min_samples_split=42, bootstrap=True, random_state=79)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    pred_proba = classifier.predict_proba(X_test.drop('order_id', axis=1))\n",
    "    submission = pd.DataFrame({\"order_id\": X_test.order_id, \"late_order\": pred_proba[:,1]})\n",
    "    submission.to_csv(\"submission_kaggle.csv\" + str(i), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
